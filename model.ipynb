{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6219a71f",
   "metadata": {
    "papermill": {
     "duration": 0.008386,
     "end_time": "2025-03-01T12:30:07.118356",
     "exception": false,
     "start_time": "2025-03-01T12:30:07.109970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d89543",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:07.134787Z",
     "iopub.status.busy": "2025-03-01T12:30:07.134474Z",
     "iopub.status.idle": "2025-03-01T12:30:20.715858Z",
     "shell.execute_reply": "2025-03-01T12:30:20.715131Z"
    },
    "papermill": {
     "duration": 13.591304,
     "end_time": "2025-03-01T12:30:20.717400",
     "exception": false,
     "start_time": "2025-03-01T12:30:07.126096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b87cdd",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:20.748777Z",
     "iopub.status.busy": "2025-03-01T12:30:20.748209Z",
     "iopub.status.idle": "2025-03-01T12:30:20.753711Z",
     "shell.execute_reply": "2025-03-01T12:30:20.752910Z"
    },
    "papermill": {
     "duration": 0.014946,
     "end_time": "2025-03-01T12:30:20.755046",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.740100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.17.1\n",
      "Keras: 3.5.0\n",
      "KerasNLP: 0.18.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45d35a5",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:20.785562Z",
     "iopub.status.busy": "2025-03-01T12:30:20.785269Z",
     "iopub.status.idle": "2025-03-01T12:30:20.790048Z",
     "shell.execute_reply": "2025-03-01T12:30:20.789195Z"
    },
    "papermill": {
     "duration": 0.01393,
     "end_time": "2025-03-01T12:30:20.791265",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.777335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42  # Random seed\n",
    "    preset = \"deberta_v3_extra_small_en\" # Name of pretrained models\n",
    "    sequence_length = 512  # Input sequence length\n",
    "    epochs = 3 # Training epochs\n",
    "    batch_size = 16  # Batch size\n",
    "    scheduler = 'cosine'  # Learning rate scheduler\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "    name2label = {v:k for k, v in label2name.items()}\n",
    "    class_labels = list(label2name.keys())\n",
    "    class_names = list(label2name.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a00f436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:20.821440Z",
     "iopub.status.busy": "2025-03-01T12:30:20.821172Z",
     "iopub.status.idle": "2025-03-01T12:30:20.824715Z",
     "shell.execute_reply": "2025-03-01T12:30:20.823911Z"
    },
    "papermill": {
     "duration": 0.012821,
     "end_time": "2025-03-01T12:30:20.826078",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.813257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef1bc6",
   "metadata": {
    "papermill": {
     "duration": 0.007241,
     "end_time": "2025-03-01T12:30:20.840793",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.833552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use mixed precision instead of float32 precision for training and inference to reduce training and inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41725fa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:20.855946Z",
     "iopub.status.busy": "2025-03-01T12:30:20.855717Z",
     "iopub.status.idle": "2025-03-01T12:30:20.858756Z",
     "shell.execute_reply": "2025-03-01T12:30:20.858199Z"
    },
    "papermill": {
     "duration": 0.011929,
     "end_time": "2025-03-01T12:30:20.859932",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.848003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e99a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:20.890146Z",
     "iopub.status.busy": "2025-03-01T12:30:20.889878Z",
     "iopub.status.idle": "2025-03-01T12:30:20.893158Z",
     "shell.execute_reply": "2025-03-01T12:30:20.892357Z"
    },
    "papermill": {
     "duration": 0.012489,
     "end_time": "2025-03-01T12:30:20.894362",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.881873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/llm-classification-finetuning'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d721e79",
   "metadata": {
    "papermill": {
     "duration": 0.007064,
     "end_time": "2025-03-01T12:30:20.908887",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.901823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📖 | Meta Data \n",
    "\n",
    "The competition dataset comprises user interactions from the ChatBot Arena. In each interaction, a judge presents one or more prompts to two different large language models and then indicates which model provided the more satisfactory response. The training data contains `55,000` rows, with an expected `25,000` rows in the test set.\n",
    "\n",
    "## Files\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "\n",
    "> Note that each interaction may have multiple prompts and responses, but this notebook will use only **one prompt per interaction**. You can choose to use all prompts and responses. Additionally, prompts and responses in the dataframe are provided as string-formatted lists, so they need to be converted to literal lists using `eval()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2704ab",
   "metadata": {
    "papermill": {
     "duration": 0.00709,
     "end_time": "2025-03-01T12:30:20.923225",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.916135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd22b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:20.939008Z",
     "iopub.status.busy": "2025-03-01T12:30:20.938737Z",
     "iopub.status.idle": "2025-03-01T12:30:24.462332Z",
     "shell.execute_reply": "2025-03-01T12:30:24.461496Z"
    },
    "papermill": {
     "duration": 3.533424,
     "end_time": "2025-03-01T12:30:24.463937",
     "exception": false,
     "start_time": "2025-03-01T12:30:20.930513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5748, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Train Data\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv') \n",
    "\n",
    "# Sample data\n",
    "df = df.sample(frac=0.1)\n",
    "\n",
    "# Take the first prompt and its associated response\n",
    "df[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\n",
    "df[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Label conversion\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# Show Sample\n",
    "#df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d51bc",
   "metadata": {
    "papermill": {
     "duration": 0.007292,
     "end_time": "2025-03-01T12:30:24.480139",
     "exception": false,
     "start_time": "2025-03-01T12:30:24.472847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48af8172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:24.495939Z",
     "iopub.status.busy": "2025-03-01T12:30:24.495657Z",
     "iopub.status.idle": "2025-03-01T12:30:24.508028Z",
     "shell.execute_reply": "2025-03-01T12:30:24.507342Z"
    },
    "papermill": {
     "duration": 0.021707,
     "end_time": "2025-03-01T12:30:24.509256",
     "exception": false,
     "start_time": "2025-03-01T12:30:24.487549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test Data\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "\n",
    "# Take the first prompt and response\n",
    "test_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\n",
    "test_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "test_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Show Sample\n",
    "#test_df.head()\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b99420",
   "metadata": {
    "papermill": {
     "duration": 0.007549,
     "end_time": "2025-03-01T12:30:24.524474",
     "exception": false,
     "start_time": "2025-03-01T12:30:24.516925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Contextualize Response with Prompt\n",
    "\n",
    "Contextualize each response with the prompt. For each response, we will provide the model with the same set of prompts combined with their respective response (e.g., `(P + R_A)`, `(P + R_B)`, etc.). This approach is similar to the multiple-choice question task in NLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4939745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:24.540556Z",
     "iopub.status.busy": "2025-03-01T12:30:24.540264Z",
     "iopub.status.idle": "2025-03-01T12:30:24.545076Z",
     "shell.execute_reply": "2025-03-01T12:30:24.544262Z"
    },
    "papermill": {
     "duration": 0.014266,
     "end_time": "2025-03-01T12:30:24.546321",
     "exception": false,
     "start_time": "2025-03-01T12:30:24.532055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to create options based on the prompt and choices\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # Response from Model A\n",
    "                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # Response from Model B\n",
    "                     ]\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3e245a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:24.562326Z",
     "iopub.status.busy": "2025-03-01T12:30:24.562072Z",
     "iopub.status.idle": "2025-03-01T12:30:30.161685Z",
     "shell.execute_reply": "2025-03-01T12:30:30.160918Z"
    },
    "papermill": {
     "duration": 5.609019,
     "end_time": "2025-03-01T12:30:30.162970",
     "exception": false,
     "start_time": "2025-03-01T12:30:24.553951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_label</th>\n",
       "      <th>encode_fail</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37379</th>\n",
       "      <td>2785062085</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>what does hello world mean</td>\n",
       "      <td>\"Hello, World!\" is a phrase used in computer p...</td>\n",
       "      <td>\"Hello, World!\" is a common phrase used to dis...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_a</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[Prompt: what does hello world mean\\n\\nRespons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>48259531</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>I ran a marathon in 3:12:00 weighting 84kg. Ho...</td>\n",
       "      <td>It's difficult to provide an exact answer to t...</td>\n",
       "      <td>To accurately estimate how much faster you wou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_a</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[Prompt: I ran a marathon in 3:12:00 weighting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a                 model_b  \\\n",
       "37379  2785062085  gpt-3.5-turbo-0613  codellama-34b-instruct   \n",
       "644      48259531      mistral-medium              gpt-4-0314   \n",
       "\n",
       "                                                  prompt  \\\n",
       "37379                         what does hello world mean   \n",
       "644    I ran a marathon in 3:12:00 weighting 84kg. Ho...   \n",
       "\n",
       "                                              response_a  \\\n",
       "37379  \"Hello, World!\" is a phrase used in computer p...   \n",
       "644    It's difficult to provide an exact answer to t...   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "37379  \"Hello, World!\" is a common phrase used to dis...               1   \n",
       "644    To accurately estimate how much faster you wou...               1   \n",
       "\n",
       "       winner_model_b  winner_tie      class_name  class_label  encode_fail  \\\n",
       "37379               0           0  winner_model_a            0        False   \n",
       "644                 0           0  winner_model_a            0        False   \n",
       "\n",
       "                                                 options  \n",
       "37379  [Prompt: what does hello world mean\\n\\nRespons...  \n",
       "644    [Prompt: I ran a marathon in 3:12:00 weighting...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Prompt: what does hello world mean\\n\\nResponse: \"Hello, World!\" is a phrase used in computer programming to introduce beginners to a new programming language. It is often the first program that a programmer writes when learning a new language. The program typically displays the words \"Hello, World!\" on the screen or console. It serves as a basic starting point to verify that the programming environment is set up correctly and to demonstrate the basic syntax of the language.',\n",
       " 'Prompt: what does hello world mean\\n\\nResponse: \"Hello, World!\" is a common phrase used to display a message on a computer screen. It is often used as a simple test to ensure that a computer program or system is working correctly. When a computer program is executed, it will typically print \"Hello, World!\" to the screen, indicating that the program has been executed successfully.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>encode_fail</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>I have three oranges today, I ate an orange ye...</td>\n",
       "      <td>You have two oranges today.</td>\n",
       "      <td>You still have three oranges. Eating an orange...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Prompt: I have three oranges today, I ate an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>You are a mediator in a heated political debat...</td>\n",
       "      <td>Thank you for sharing the details of the situa...</td>\n",
       "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Prompt: You are a mediator in a heated politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             prompt  \\\n",
       "0  136060  I have three oranges today, I ate an orange ye...   \n",
       "1  211333  You are a mediator in a heated political debat...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                        You have two oranges today.   \n",
       "1  Thank you for sharing the details of the situa...   \n",
       "\n",
       "                                          response_b  encode_fail  \\\n",
       "0  You still have three oranges. Eating an orange...        False   \n",
       "1  Mr Reddy and Ms Blue both have valid points in...        False   \n",
       "\n",
       "                                             options  \n",
       "0  [Prompt: I have three oranges today, I ate an ...  \n",
       "1  [Prompt: You are a mediator in a heated politi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\n",
    "display(df.head(2))  # Display the first 2 rows of df\n",
    "display(df[\"options\"].iloc[0])\n",
    "\n",
    "test_df = test_df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\n",
    "display(test_df.head(2))  # Display the first 2 rows of df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02768ffa",
   "metadata": {
    "papermill": {
     "duration": 0.007744,
     "end_time": "2025-03-01T12:30:30.302473",
     "exception": false,
     "start_time": "2025-03-01T12:30:30.294729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing - Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2909499d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:30.319387Z",
     "iopub.status.busy": "2025-03-01T12:30:30.319119Z",
     "iopub.status.idle": "2025-03-01T12:30:36.704533Z",
     "shell.execute_reply": "2025-03-01T12:30:36.703787Z"
    },
    "papermill": {
     "duration": 6.39571,
     "end_time": "2025-03-01T12:30:36.706221",
     "exception": false,
     "start_time": "2025-03-01T12:30:30.310511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset, # Name of the model\n",
    "    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ed25f",
   "metadata": {
    "papermill": {
     "duration": 0.007875,
     "end_time": "2025-03-01T12:30:36.722618",
     "exception": false,
     "start_time": "2025-03-01T12:30:36.714743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_responses, sequence\\_length)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a9af0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:36.739892Z",
     "iopub.status.busy": "2025-03-01T12:30:36.739619Z",
     "iopub.status.idle": "2025-03-01T12:30:37.938203Z",
     "shell.execute_reply": "2025-03-01T12:30:37.937478Z"
    },
    "papermill": {
     "duration": 1.208864,
     "end_time": "2025-03-01T12:30:37.939597",
     "exception": false,
     "start_time": "2025-03-01T12:30:36.730733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids : (2, 512)\n",
      "padding_mask : (2, 512)\n"
     ]
    }
   ],
   "source": [
    "outs = preprocessor(df.options.iloc[0])  # Process options for the first row\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2a26a",
   "metadata": {
    "papermill": {
     "duration": 0.007902,
     "end_time": "2025-03-01T12:30:37.956122",
     "exception": false,
     "start_time": "2025-03-01T12:30:37.948220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a6e28f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:37.973050Z",
     "iopub.status.busy": "2025-03-01T12:30:37.972799Z",
     "iopub.status.idle": "2025-03-01T12:30:37.976064Z",
     "shell.execute_reply": "2025-03-01T12:30:37.975476Z"
    },
    "papermill": {
     "duration": 0.013182,
     "end_time": "2025-03-01T12:30:37.977297",
     "exception": false,
     "start_time": "2025-03-01T12:30:37.964115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571135c3",
   "metadata": {
    "papermill": {
     "duration": 0.007787,
     "end_time": "2025-03-01T12:30:37.993075",
     "exception": false,
     "start_time": "2025-03-01T12:30:37.985288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eca6388",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:38.009651Z",
     "iopub.status.busy": "2025-03-01T12:30:38.009381Z",
     "iopub.status.idle": "2025-03-01T12:30:38.014206Z",
     "shell.execute_reply": "2025-03-01T12:30:38.013387Z"
    },
    "papermill": {
     "duration": 0.014492,
     "end_time": "2025-03-01T12:30:38.015478",
     "exception": false,
     "start_time": "2025-03-01T12:30:38.000986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds  # Return the built dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c309717c",
   "metadata": {
    "papermill": {
     "duration": 0.00838,
     "end_time": "2025-03-01T12:30:38.360275",
     "exception": false,
     "start_time": "2025-03-01T12:30:38.351895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Checkpointing\n",
    "\n",
    "Create a callback that will save the best checkpoint of the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72b0991",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:38.378313Z",
     "iopub.status.busy": "2025-03-01T12:30:38.378063Z",
     "iopub.status.idle": "2025-03-01T12:30:38.381530Z",
     "shell.execute_reply": "2025-03-01T12:30:38.380709Z"
    },
    "papermill": {
     "duration": 0.013858,
     "end_time": "2025-03-01T12:30:38.382827",
     "exception": false,
     "start_time": "2025-03-01T12:30:38.368969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',\n",
    "                                          save_best_only=True,\n",
    "                                          save_weights_only=True,\n",
    "                                          mode='min')  # Get Model checkpoint callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b600043",
   "metadata": {
    "papermill": {
     "duration": 0.008405,
     "end_time": "2025-03-01T12:30:38.401179",
     "exception": false,
     "start_time": "2025-03-01T12:30:38.392774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3cec343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:38.419003Z",
     "iopub.status.busy": "2025-03-01T12:30:38.418783Z",
     "iopub.status.idle": "2025-03-01T12:30:38.447941Z",
     "shell.execute_reply": "2025-03-01T12:30:38.447293Z"
    },
    "papermill": {
     "duration": 0.03932,
     "end_time": "2025-03-01T12:30:38.449133",
     "exception": false,
     "start_time": "2025-03-01T12:30:38.409813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e7353",
   "metadata": {
    "papermill": {
     "duration": 0.00848,
     "end_time": "2025-03-01T12:30:38.466450",
     "exception": false,
     "start_time": "2025-03-01T12:30:38.457970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d274d63d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:38.484223Z",
     "iopub.status.busy": "2025-03-01T12:30:38.484010Z",
     "iopub.status.idle": "2025-03-01T12:30:46.737796Z",
     "shell.execute_reply": "2025-03-01T12:30:46.737051Z"
    },
    "papermill": {
     "duration": 8.264562,
     "end_time": "2025-03-01T12:30:46.739480",
     "exception": false,
     "start_time": "2025-03-01T12:30:38.474918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input layers\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "# Create a DebertaV3Classifier backbone\n",
    "backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "    CFG.preset,\n",
    ")\n",
    "\n",
    "# Compute embeddings for first response: (P + R_A) using backbone\n",
    "response_a = {k: v[:, 0, :] for k, v in inputs.items()}\n",
    "embed_a = backbone(response_a)\n",
    "\n",
    "# Compute embeddings for second response: (P + R_B), using the same backbone\n",
    "response_b = {k: v[:, 1, :] for k, v in inputs.items()}\n",
    "embed_b = backbone(response_b)\n",
    "\n",
    "# Compute final output\n",
    "embeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\n",
    "embeds = keras.layers.GlobalAveragePooling1D()(embeds)\n",
    "outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model with optimizer, loss, and metrics\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(9e-6),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n",
    "    metrics=[\n",
    "        log_loss,\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c83ac",
   "metadata": {
    "papermill": {
     "duration": 0.008899,
     "end_time": "2025-03-01T12:30:46.757761",
     "exception": false,
     "start_time": "2025-03-01T12:30:46.748862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25eaf702",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:46.777055Z",
     "iopub.status.busy": "2025-03-01T12:30:46.776775Z",
     "iopub.status.idle": "2025-03-01T12:30:46.800212Z",
     "shell.execute_reply": "2025-03-01T12:30:46.799441Z"
    },
    "papermill": {
     "duration": 0.034629,
     "end_time": "2025-03-01T12:30:46.801781",
     "exception": false,
     "start_time": "2025-03-01T12:30:46.767152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ deberta_v3_backbone       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">70,682,112</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DebertaV3Backbone</span>)       │                        │                │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                           │                        │                │ get_item_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                           │                        │                │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ deberta_v3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                           │                        │                │ deberta_v3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,307</span> │ global_average_poolin… │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;45mNone\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;45mNone\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item_1 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item_3 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ get_item_2 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ deberta_v3_backbone       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │     \u001b[38;5;34m70,682,112\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mDebertaV3Backbone\u001b[0m)       │                        │                │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                           │                        │                │ get_item_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                           │                        │                │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ deberta_v3_backbone[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                           │                        │                │ deberta_v3_backbone[\u001b[38;5;34m1\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │          \u001b[38;5;34m2,307\u001b[0m │ global_average_poolin… │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,684,419</span> (269.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,684,419\u001b[0m (269.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,684,419</span> (269.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,684,419\u001b[0m (269.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf8c1dc",
   "metadata": {
    "papermill": {
     "duration": 0.009105,
     "end_time": "2025-03-01T12:30:46.864933",
     "exception": false,
     "start_time": "2025-03-01T12:30:46.855828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3b3c2",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-01T12:30:46.884031Z",
     "iopub.status.busy": "2025-03-01T12:30:46.883799Z",
     "iopub.status.idle": "2025-03-01T12:53:13.843191Z",
     "shell.execute_reply": "2025-03-01T12:53:13.842231Z"
    },
    "papermill": {
     "duration": 1347.029685,
     "end_time": "2025-03-01T12:53:13.903790",
     "exception": false,
     "start_time": "2025-03-01T12:30:46.874105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - accuracy: 0.3716 - log_loss: 1.1814 - loss: 1.1831 - val_accuracy: 0.4315 - val_log_loss: 1.0686 - val_loss: 1.0706\n",
      "Epoch 2/3\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 1s/step - accuracy: 0.4403 - log_loss: 1.0595 - loss: 1.0617 - val_accuracy: 0.4489 - val_log_loss: 1.0592 - val_loss: 1.0614\n",
      "Epoch 3/3\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 1s/step - accuracy: 0.4699 - log_loss: 1.0325 - loss: 1.0353 - val_accuracy: 0.4499 - val_log_loss: 1.0590 - val_loss: 1.0614\n",
      "Epoch 1/3\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 1s/step - accuracy: 0.4597 - log_loss: 1.0595 - loss: 1.0619 - val_accuracy: 0.5188 - val_log_loss: 0.9900 - val_loss: 0.9939\n",
      "Epoch 2/3\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 1s/step - accuracy: 0.4939 - log_loss: 1.0237 - loss: 1.0270 - val_accuracy: 0.5181 - val_log_loss: 0.9926 - val_loss: 0.9966\n",
      "Epoch 3/3\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 1s/step - accuracy: 0.5232 - log_loss: 0.9922 - loss: 0.9962 - val_accuracy: 0.5143 - val_log_loss: 0.9937 - val_loss: 0.9978\n"
     ]
    }
   ],
   "source": [
    "# 2-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "for train, valid in kf.split(df):\n",
    "    # Train\n",
    "    train_df = df.iloc[train]\n",
    "    train_texts = train_df.options.tolist()  # Extract training texts\n",
    "    train_labels = train_df.class_label.tolist()  # Extract training labels\n",
    "    train_ds = build_dataset(train_texts, train_labels,\n",
    "                             batch_size=CFG.batch_size,\n",
    "                             shuffle=True)\n",
    "    \n",
    "    # Valid\n",
    "    valid_df = df.iloc[valid]\n",
    "    valid_texts = valid_df.options.tolist()  # Extract validation texts\n",
    "    valid_labels = valid_df.class_label.tolist()  # Extract validation labels\n",
    "    valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                             batch_size=CFG.batch_size,\n",
    "                             shuffle=False)    \n",
    "\n",
    "    # Start training the model\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=CFG.epochs,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=ckpt_cb\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df13c1c",
   "metadata": {
    "papermill": {
     "duration": 0.059553,
     "end_time": "2025-03-01T12:53:14.026097",
     "exception": false,
     "start_time": "2025-03-01T12:53:13.966544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Best Model\n",
    "\n",
    "After training, load the weight with best result to get the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73dda953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:53:14.148207Z",
     "iopub.status.busy": "2025-03-01T12:53:14.147886Z",
     "iopub.status.idle": "2025-03-01T12:53:15.921847Z",
     "shell.execute_reply": "2025-03-01T12:53:15.921121Z"
    },
    "papermill": {
     "duration": 1.837181,
     "end_time": "2025-03-01T12:53:15.923428",
     "exception": false,
     "start_time": "2025-03-01T12:53:14.086247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights('/kaggle/working/best_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2995f51e",
   "metadata": {
    "papermill": {
     "duration": 0.059704,
     "end_time": "2025-03-01T12:53:16.045801",
     "exception": false,
     "start_time": "2025-03-01T12:53:15.986097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a8031ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:53:16.168719Z",
     "iopub.status.busy": "2025-03-01T12:53:16.168358Z",
     "iopub.status.idle": "2025-03-01T12:53:16.522414Z",
     "shell.execute_reply": "2025-03-01T12:53:16.521580Z"
    },
    "papermill": {
     "duration": 0.418355,
     "end_time": "2025-03-01T12:53:16.523957",
     "exception": false,
     "start_time": "2025-03-01T12:53:16.105602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build test dataset\n",
    "test_texts = test_df.options.tolist()\n",
    "test_ds = build_dataset(test_texts,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fdee108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:53:16.650492Z",
     "iopub.status.busy": "2025-03-01T12:53:16.650191Z",
     "iopub.status.idle": "2025-03-01T12:53:23.023915Z",
     "shell.execute_reply": "2025-03-01T12:53:23.023220Z"
    },
    "papermill": {
     "duration": 6.437615,
     "end_time": "2025-03-01T12:53:23.025237",
     "exception": false,
     "start_time": "2025-03-01T12:53:16.587622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the trained model on test data\n",
    "test_preds = model.predict(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb2a64",
   "metadata": {
    "papermill": {
     "duration": 0.060156,
     "end_time": "2025-03-01T12:53:23.147963",
     "exception": false,
     "start_time": "2025-03-01T12:53:23.087807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Following code will prepare the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "104d1f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T12:53:23.269333Z",
     "iopub.status.busy": "2025-03-01T12:53:23.269029Z",
     "iopub.status.idle": "2025-03-01T12:53:23.285633Z",
     "shell.execute_reply": "2025-03-01T12:53:23.284784Z"
    },
    "papermill": {
     "duration": 0.078625,
     "end_time": "2025-03-01T12:53:23.286904",
     "exception": false,
     "start_time": "2025-03-01T12:53:23.208279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.230835</td>\n",
       "      <td>0.268066</td>\n",
       "      <td>0.500977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.495605</td>\n",
       "      <td>0.197388</td>\n",
       "      <td>0.306641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.405029</td>\n",
       "      <td>0.356445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.230835        0.268066    0.500977\n",
       "1   211333        0.495605        0.197388    0.306641\n",
       "2  1233961        0.238281        0.405029    0.356445"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df[[\"id\"]].copy()\n",
    "sub_df[CFG.class_names] = test_preds.tolist()\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1402.11173,
   "end_time": "2025-03-01T12:53:26.654100",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-01T12:30:04.542370",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
